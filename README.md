# car_classification
# Проект по классификации автомобилей

Данный проект разработан для демонстрации возможности нейронных сетей по распознаванию популярных в России моделей автомобилей, а так же споособов интеграции обученной модели. Набор данных состоит из 5 моделей: по 28 изображений для тренировочной выборки и 7 валидационной.
Генерация дасетов изображений осуществляется с помощью ImageDataGenerator библиотеки keras.
Работа состоит из нескольких частей:
1. Часть посвящена предподготовке данных, настройке, обучению и анализу модели (описать выбранную модель и применение Imagedatagenerator) ipynd.
2. Развертывание модели на Docker и тестирование на запущенной модели heroku.

# 2 Развертывание модели с помощью TensorFlow Serving
[TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving) — это гибкая высокопроизводительная система обслуживания моделей машинного обучения, разработанная для производственных сред. TensorFlow Serving упрощает развертывание новых алгоритмов и экспериментов, сохраняя при этом ту же архитектуру сервера и API. TensorFlow Serving обеспечивает готовую интеграцию с моделями TensorFlow, но может быть легко расширен для обслуживания других типов моделей. 

Проще говоря, TensorFlow Serving позволяет легко обслуживать модель через сервер моделей. Он предоставляет гибкий API, который можно легко интегрировать в существующую систему или развернуть на облачных платформах. 

# 2.1 Развертывание модели мы будем осуществлять на Ubuntu 20.04 с помощью Docker, а после полученный контейнер интегируем на виртуальную машину  Heroku.

Порядок установки Docker берем из офциального руководства  ( https://docs.docker.com/engine/install/ubuntu/).
Проверить корректность установки Dockera можно выполнив команду в терминале:
  ~$ docker run hello-world

и в случае правильной установки вы плучите сообщение:

Hello from Docker!
This message shows that your installation appears to be working correctly.

# 2.2 Установка обслуживания Tensorflow
Теперь, когда у вас правильно установлен Docker, вы собираетесь использовать его для загрузки TF Serving. 
(все операции выполняются в окне терминала, открытого в главном разделе проекта)
В терминале выполните следующую команду:

 ~$  docker pull tensorflow/serving:latest-gpu 
 
 а если вы хотите использовать CPU то: 
 
 ~$ docker pull tensorflow/serving:latest-gpu 
 
 и в случае правильной установки вы плучите сообщение:

Status: Image is up to date for tensorflow/serving:latest-gpu
docker.io/tensorflow/serving:latest-gpu

# 2.3 Обслуживание сохраненной модели с помощью Tensorflow Serving
Папка с сохраненной моделью должна быть представлена в следющем виде:
├── img_classifier 
│ ├── 1600788643 
│ │ ├── assets 
│ │ ├── save_model.pb 
│ │ └── переменные
 
Подробный порядок развертывания модели описан в [руководстве](https://www.tensorflow.org/tfx/tutorials/serving/rest_simple).




